{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithme de base de région de confiance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "# using Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct BasicTrustRegion{T <: Real}\n",
    "    η1:: T\n",
    "    η2:: T\n",
    "    γ1:: T\n",
    "    γ2:: T\n",
    "end\n",
    "\n",
    "function BTRDefaults()\n",
    "    return BasicTrustRegion(0.01,0.9,0.5,0.5)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'état de l'algorithme est déclaré avec le mot clé addtionnel `mutable` comme le contenu peut être modifié d'itération en itération."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct BTRState\n",
    "    iter::Int\n",
    "    x::Vector\n",
    "    xcand::Vector\n",
    "    g::Vector\n",
    "    step::Vector\n",
    "    Δ::Float64\n",
    "    ρ::Float64\n",
    "    \n",
    "    function BTRState()\n",
    "        return new()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function acceptCandidate!(state::BTRState, b::BasicTrustRegion)\n",
    "    # If the iteration is successful, update the iterate\n",
    "    if (state.ρ >= b.η1)\n",
    "        state.x = copy(state.xcand) # x[:] = state.xcand\n",
    "        return true\n",
    "    else\n",
    "        return false\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function updateRadius!(state::BTRState, b::BasicTrustRegion)\n",
    "    if (state.ρ >= b.η2)\n",
    "        # very successful iterate\n",
    "        state.Δ = min(1e20,max(4*norm(state.step),state.Δ))\n",
    "    elseif (state.ρ >= b.η1)\n",
    "        # successful iterate\n",
    "        state.Δ *= b.γ2\n",
    "    else\n",
    "        # unsuccessful iterate\n",
    "        state.Δ *= b.γ1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pas de Cauchy\n",
    "\n",
    "Calculons et vérifions la valeur du pas de Cauchy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sait que\n",
    "$$\n",
    "\\alpha^* =\n",
    "\\begin{cases}\n",
    "\\min \\left\\{ \\frac{\\Delta_k}{\\| \\nabla f(x_k) \\|_k}, \\frac{\\| \\nabla f(x_k) \\|_2^2}{\\nabla f(x_k)^T H_k \\nabla f(x_k)}  \\right\\} & \\text{si } \\nabla f(x_k)^T H_k \\nabla f(x_k) > 0 \\\\\n",
    "\\frac{\\Delta_k}{\\| \\nabla f(x_k) \\|_k} & \\text{sinon.}\n",
    "\\end{cases}\n",
    "$$\n",
    "Le pas de Cauchy est alors\n",
    "$$\n",
    "s_k = -\\alpha^*\\nabla f(x^*).\n",
    "$$\n",
    "Dans la suite, nous utiliserons la norme euclidienne, i.e. $\\| \\cdot \\|_k = \\| \\cdot \\|_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soit\n",
    "$$\n",
    "q = \\nabla f(x_k)^T H_k \\nabla f(x_k)\n",
    "$$\n",
    "Si $q \\leq 0$, nous sommes dans une direction de courbure non positive, et nous devons nous devons rendre à la frontière. Dès lors\n",
    "$$\n",
    "s_k = - \\frac{\\Delta_k}{\\| \\nabla f(x_k) \\|_k} \\nabla f(x_k).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $q > 0$, nous devons vérifier si le minimum du modèle le long de la plus forte pente est à l'intérieur de la région de confiance. Si c'est le cas, nous avons\n",
    "\\begin{align*}\n",
    "s_k &= - \\frac{\\| \\nabla f(x_k) \\|_2^2}{\\nabla f(x_k)^T H_k \\nabla f(x_k)} \\nabla f(x_k) \\\\\n",
    "&= - \\frac{\\| \\nabla f(x_k) \\|_2^2}{\\nabla f(x_k)^T H_k \\nabla f(x_k)} \\nabla f(x_k) \\frac{\\Delta_k}{\\| \\nabla f(x_k) \\|_k}\n",
    "\\frac{\\| \\nabla f(x_k) \\|_k}{\\Delta_k} \\\\\n",
    "&= - \\frac{\\| \\nabla f(x_k) \\|_2^3}{\\Delta_k \\nabla f(x_k)^T H_k \\nabla f(x_k)} \\frac{\\Delta_k}{\\| \\nabla f(x_k) \\|_k} \\nabla f(x_k) \\\\\n",
    "&= - \\tau \\frac{\\Delta_k}{\\| \\nabla f(x_k) \\|_k} \\nabla f(x_k),\n",
    "\\end{align*}\n",
    "où\n",
    "$$\n",
    "\\tau = \\frac{\\| \\nabla f(x_k) \\|_2^3}{\\Delta_k q}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ce n'est pas le cas, nous nous arrêtons sur la frontière de la région de confiance, et nous avons à nouveau\n",
    "$$\n",
    "s_k = - \\frac{\\Delta_k}{\\| \\nabla f(x_k) \\|_k} \\nabla f(x_k).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En regroupant ces deux cas, nous avons\n",
    "$$\n",
    "s_k = - \\tau \\frac{\\Delta_k}{\\| \\nabla f(x_k) \\|_k} \\nabla f(x_k),\n",
    "$$\n",
    "avec\n",
    "$$\n",
    "\\tau = \\min \\left\\{ 1.0, \\frac{\\| \\nabla f(x_k) \\|_2^3}{\\Delta_k q} \\right\\}.\n",
    "$$\n",
    "Ceci permet de construire le code ci-après."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function CauchyStep(g::Vector,H::Matrix,Δ::Float64)\n",
    "    q = dot(g,H*g)\n",
    "    normg = norm(g)\n",
    "\n",
    "    if (q <= 0)\n",
    "        # the curvature along g is non positive\n",
    "        τ = 1.0\n",
    "    else\n",
    "        # the curvature along g is positive\n",
    "        τ = min((normg*normg*normg)/(q*Δ),1.0)\n",
    "    end\n",
    "\n",
    "    return -τ*g*Δ/normg # return the step\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme de base de région de confiance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "function btr(f::Function, g!::Function, H!::Function,\n",
    "    x0::Vector, tol::Float64 = 1e-6, verbose::Bool = false)\n",
    "    \n",
    "    b = BTRDefaults()\n",
    "    state = BTRState()\n",
    "    state.iter = 0\n",
    "    state.x = x0\n",
    "    n=length(x0)\n",
    "\n",
    "    state.g = zeros(n)\n",
    "    H = zeros(n,n)\n",
    "    \n",
    "    fx = f(x0)\n",
    "    g!(state.g, x0)\n",
    "    H!(H, x0)\n",
    "\n",
    "    state.Δ = init_radius(state)\n",
    "    \n",
    "    nmax = 100000\n",
    "    \n",
    "    tol2 = tol*tol\n",
    "    \n",
    "    function model(s::Vector, g::Vector, H::Matrix)\n",
    "        return dot(s, g)+0.5*dot(s, H*s)\n",
    "    end\n",
    "    \n",
    "    if (verbose)\n",
    "        println(state)\n",
    "    end\n",
    "\n",
    "    while (dot(state.g,state.g) > tol2 && state.iter < nmax)\n",
    "        # Compute the step by approximately minimize the model\n",
    "        state.step = CauchyStep(state.g, H, state.Δ)\n",
    "        state.xcand = state.x+state.step\n",
    "\n",
    "        # Compute the actual reduction over the predicted reduction\n",
    "        fcand = f(state.xcand)\n",
    "        state.ρ = (fcand-fx)/(model(state.step, state.g, H))\n",
    "\n",
    "        if (acceptCandidate!(state, b))\n",
    "            g!(state.g, state.x)\n",
    "            H!(H, state.x)\n",
    "            fx = fcand\n",
    "        end\n",
    "\n",
    "        if (verbose)\n",
    "            println(state)\n",
    "        end\n",
    "        \n",
    "        updateRadius!(state, b)\n",
    "        state.iter += 1\n",
    "    end\n",
    "    \n",
    "    return state\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function init_radius(state:: BTRState)\n",
    "    return 1.0\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de Rosenbrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "function rosenbrock(x::Vector)\n",
    "    return (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2\n",
    "end\n",
    "\n",
    "function rosenbrock_gradient!(storage::Vector, x::Vector)\n",
    "    storage[1] = -2.0 * (1.0 - x[1]) - 400.0 * (x[2] - x[1]^2) * x[1]\n",
    "    storage[2] = 200.0 * (x[2] - x[1]^2)\n",
    "end\n",
    "\n",
    "function rosenbrock_hessian!(storage::Matrix, x::Vector)\n",
    "    storage[1, 1] = 2.0 - 400.0 * x[2] + 1200.0 * x[1]^2\n",
    "    storage[1, 2] = -400.0 * x[1]\n",
    "    storage[2, 1] = -400.0 * x[1]\n",
    "    storage[2, 2] = 200.0\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "state = btr(rosenbrock, rosenbrock_gradient!, rosenbrock_hessian!, [0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.Δ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions la première itération, en partant de (0,0). Afin de calculer la longueur du pas, nous devons d'abord connaître le gradient et la matrice hessienne en (0,0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0; 0]\n",
    "grad=zeros(2)\n",
    "hess=zeros(2,2)\n",
    "rosenbrock_gradient!(grad,x)\n",
    "rosenbrock_hessian!(hess,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous savons que\n",
    "$$\n",
    "\\alpha^* = \\min\n",
    "\\left\\{\n",
    "\\frac{\\Delta_k}{\\| \\nabla f(x_k) \\|_k},\n",
    "\\frac{\\| \\nabla f(x_k) \\|_2^2}{\\nabla f(x_k)^T H_k \\nabla f(x_k)}\n",
    "\\right\\}\n",
    "$$\n",
    "Le premier terme de la minimisation est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0/norm(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le second est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot(grad,grad)/dot(grad,hess*grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dès lors $\\alpha^* = 0.5$ et $x_1 = (0,0) + 0.5*\\nabla f(0.0) = (1,0)$. Nous pouvons facilement vérifier cette valeur en regardand les premières itérations de la procédure d'optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = btr(rosenbrock, rosenbrock_gradient!, rosenbrock_hessian!, [0,0], 1.0, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ForwardDiff\n",
    "\n",
    "f(x) = x[1]^4 + x[1]^2 + x[1]*x[2] + (1+x[2])^2\n",
    "g = x -> ForwardDiff.gradient(f, x);\n",
    "H = x -> ForwardDiff.hessian(f, x);\n",
    "function g!(storage::Vector, x::Vector)\n",
    "    s = g(x)\n",
    "    storage[1:length(s)] = s[1:length(s)]\n",
    "end\n",
    "function H!(storage::Matrix, x::Vector)\n",
    "    s = H(x)\n",
    "    n, m = size(s)\n",
    "    storage[1:n,1:m] = s[1:length(s)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = btr(f, g!, H!, [0,0], 1e-6, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation du rayon de la région de confiance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code précédent défini arbitrairement le rayon initial de la région de confiance avec la valeur 1. Cette valeur peut se révéler trop petite, et un grand nombre d'itérations sont nécessaires avant d'obtenir un voisinage assez grand, ou trop grand, conduisant à de nombreuses itérations non réussies en début d'exécution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs approches ont été proposées dans la littérature. Une heuristique populaire, proposée initialement dans le logiciel `Lancelot`, est de définir\n",
    "$$\n",
    "\\Delta_0 = \\kappa \\| \\nabla f(x_0) \\|,\n",
    "$$\n",
    "où $x_0$ est le point de départ et $\\kappa > 0$. On pourra prendre $\\kappa = 0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function init_radius(state:: BTRState)\n",
    "    return 0.1*norm(state.g)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = btr(rosenbrock, rosenbrock_gradient!, rosenbrock_hessian!, [0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est nettement mieux!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = btr(f, g!, H!, [0,0], 1.0, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = btr(f, g!, H!, [0,0], 1e-6, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que ce n'est pas toujours efficace!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
